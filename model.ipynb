{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.0.92 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.84  Python-3.9.12 torch-2.0.0+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=config.yaml, epochs=32, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=Road Crack Detection, name=None, exist_ok=False, pretrained=False, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=Road Crack Detection\\train2\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.Detect                [7, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3012213 parameters, 3012197 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Charan Chakkara\\Documents\\GitHub\\Road Crack Detection 2\\dataset\\train\\labels.cache... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<?, ?it/s]\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 25, len(boxes) = 165. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Charan Chakkara\\Documents\\GitHub\\Road Crack Detection 2\\dataset\\train\\labels.cache... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<?, ?it/s]\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 25, len(boxes) = 165. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to Road Crack Detection\\train2\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mRoad Crack Detection\\train2\u001b[0m\n",
      "Starting training for 32 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/32         0G      3.628      4.796      4.011         14        640: 100%|██████████| 8/8 [00:51<00:00,  6.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  5.00s/it]\n",
      "                   all        121        165    0.00011     0.0483   0.000101   3.27e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/32         0G      3.478      4.463      3.665         30        640: 100%|██████████| 8/8 [00:50<00:00,  6.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.02s/it]\n",
      "                   all        121        165   0.000181     0.0888    0.00432   0.000796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/32         0G      3.534      4.292      3.535         21        640: 100%|██████████| 8/8 [00:50<00:00,  6.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.20s/it]\n",
      "                   all        121        165   0.000299      0.111    0.00331   0.000721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/32         0G      3.431      4.298      3.477         20        640: 100%|██████████| 8/8 [00:48<00:00,  6.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.14s/it]\n",
      "                   all        121        165      0.286     0.0598    0.00361   0.000966\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/32         0G       3.46      4.298      3.383         22        640: 100%|██████████| 8/8 [00:50<00:00,  6.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.31s/it]\n",
      "                   all        121        165      0.429     0.0405    0.00424    0.00116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/32         0G      3.469      4.335      3.398         28        640: 100%|██████████| 8/8 [00:52<00:00,  6.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.44s/it]\n",
      "                   all        121        165    0.00055      0.115   0.000927   0.000244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/32         0G      3.336      4.316      3.379         24        640: 100%|██████████| 8/8 [00:50<00:00,  6.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:23<00:00,  5.86s/it]\n",
      "                   all        121        165   0.000316     0.0898   0.000257   6.53e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/32         0G      3.283      4.301       3.33         26        640: 100%|██████████| 8/8 [00:51<00:00,  6.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.39s/it]\n",
      "                   all        121        165   0.000507       0.12   0.000374   0.000104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/32         0G       3.37      4.288      3.358         26        640: 100%|██████████| 8/8 [00:50<00:00,  6.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.16s/it]\n",
      "                   all        121        165      0.429     0.0235   0.000323   7.64e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/32         0G      3.255       4.37      3.341         35        640: 100%|██████████| 8/8 [00:52<00:00,  6.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.91s/it]\n",
      "                   all        121        165      0.429    0.00981    0.00012   3.74e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/32         0G      3.224      4.331      3.337         17        640: 100%|██████████| 8/8 [00:52<00:00,  6.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.04s/it]\n",
      "                   all        121        165      0.429    0.00981    0.00012   3.74e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/32         0G       3.09      4.264      3.297         28        640: 100%|██████████| 8/8 [00:49<00:00,  6.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n",
      "                   all        121        165   3.24e-05    0.00579   1.71e-05   2.86e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/32         0G      3.056      4.288      3.254         25        640: 100%|██████████| 8/8 [00:49<00:00,  6.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.77s/it]\n",
      "                   all        121        165   2.07e-05    0.00193   6.81e-05   1.72e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/32         0G      3.157      4.293      3.281         26        640: 100%|██████████| 8/8 [00:49<00:00,  6.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.79s/it]\n",
      "                   all        121        165      0.572    0.00193   0.000105   2.64e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/32         0G      3.131      4.284      3.281         22        640: 100%|██████████| 8/8 [00:49<00:00,  6.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.00s/it]\n",
      "                   all        121        165      0.286     0.0347   0.000841   0.000225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/32         0G      3.191      4.337      3.216         30        640: 100%|██████████| 8/8 [00:52<00:00,  6.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.23s/it]\n",
      "                   all        121        165   0.000633       0.13   0.000622   0.000205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/32         0G      3.064      4.325      3.152         23        640: 100%|██████████| 8/8 [00:51<00:00,  6.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.10s/it]\n",
      "                   all        121        165   0.000825      0.108   0.000614   0.000161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/32         0G      3.103      4.237      3.228         31        640: 100%|██████████| 8/8 [00:53<00:00,  6.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:22<00:00,  5.51s/it]\n",
      "                   all        121        165   0.000567        0.1   0.000952   0.000274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/32         0G       3.11      4.323      3.197         20        640: 100%|██████████| 8/8 [00:50<00:00,  6.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.48s/it]\n",
      "                   all        121        165   0.000663      0.157    0.00159   0.000481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/32         0G      3.125       4.29      3.122         29        640: 100%|██████████| 8/8 [00:52<00:00,  6.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.31s/it]\n",
      "                   all        121        165      0.144      0.056    0.00147   0.000346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/32         0G      3.049      4.285       3.17         34        640: 100%|██████████| 8/8 [00:51<00:00,  6.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.29s/it]\n",
      "                   all        121        165      0.144     0.0734    0.00441    0.00101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/32         0G      2.901      4.242      3.104         31        640: 100%|██████████| 8/8 [00:51<00:00,  6.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.19s/it]\n",
      "                   all        121        165    0.00129      0.151    0.00405    0.00135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/32         0G      2.923      4.281      3.062         20        640: 100%|██████████| 8/8 [00:49<00:00,  6.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.20s/it]\n",
      "                   all        121        165   0.000851      0.184    0.00365   0.000883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/32         0G      2.915      4.183      3.067         19        640: 100%|██████████| 8/8 [00:53<00:00,  6.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.14s/it]\n",
      "                   all        121        165   0.000834      0.184    0.00506    0.00111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/32         0G       2.94      4.295      3.125         23        640: 100%|██████████| 8/8 [00:51<00:00,  6.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.97s/it]\n",
      "                   all        121        165   0.000821      0.174    0.00186   0.000464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/32         0G      2.875      4.247      3.026         25        640: 100%|██████████| 8/8 [00:48<00:00,  6.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.94s/it]\n",
      "                   all        121        165   0.000911       0.18    0.00145   0.000344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/32         0G      2.903      4.328      3.044         31        640: 100%|██████████| 8/8 [00:49<00:00,  6.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.91s/it]\n",
      "                   all        121        165   0.000932      0.172    0.00136   0.000323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/32         0G      2.808      4.293          3         18        640: 100%|██████████| 8/8 [00:51<00:00,  6.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.18s/it]\n",
      "                   all        121        165   0.000938       0.16    0.00155   0.000369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/32         0G      2.728      4.211      2.974         18        640: 100%|██████████| 8/8 [00:52<00:00,  6.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:21<00:00,  5.36s/it]\n",
      "                   all        121        165   0.000968      0.164    0.00229   0.000468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/32         0G      2.728      4.207      2.956         21        640: 100%|██████████| 8/8 [00:50<00:00,  6.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.99s/it]\n",
      "                   all        121        165   0.000761      0.154    0.00236   0.000505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/32         0G      2.717      4.221      2.949         25        640: 100%|██████████| 8/8 [00:49<00:00,  6.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.03s/it]\n",
      "                   all        121        165   0.000792      0.164    0.00239    0.00046\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/32         0G      2.838      4.244      2.959         28        640: 100%|██████████| 8/8 [00:49<00:00,  6.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.08s/it]\n",
      "                   all        121        165   0.000852      0.185    0.00189    0.00037\n",
      "\n",
      "32 epochs completed in 0.638 hours.\n",
      "Optimizer stripped from Road Crack Detection\\train2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from Road Crack Detection\\train2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating Road Crack Detection\\train2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.84  Python-3.9.12 torch-2.0.0+cpu CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:17<00:00,  4.40s/it]\n",
      "                   all        121        165    0.00129      0.151    0.00405    0.00135\n",
      "                   D01        121         25   0.000611       0.12   0.000519   9.53e-05\n",
      "                   D10        121          1          0          0          0          0\n",
      "                   D11        121         24    0.00223      0.292    0.00253   0.000579\n",
      "                   D20        121          1          0          0          0          0\n",
      "                   D40        121         37    0.00133      0.189    0.00159   0.000331\n",
      "                   D43        121         74    0.00484      0.459     0.0237    0.00845\n",
      "                   D44        121          3          0          0          0          0\n",
      "Speed: 2.0ms preprocess, 121.7ms inference, 0.0ms loss, 9.5ms postprocess per image\n",
      "Results saved to \u001b[1mRoad Crack Detection\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model=YOLO(\"yolov8n.yaml\")\n",
    "results=model.train(data=\"config.yaml\",epochs=32,workers=4,project=\"Road Crack Detection\",optimizer=\"Adam\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.84  Python-3.9.12 torch-2.0.0+cpu CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Charan Chakkara\\Documents\\GitHub\\Road Crack Detection 2\\dataset\\train\\labels.cache... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<?, ?it/s]\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 25, len(boxes) = 165. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.25s/it]\n",
      "                   all        121        165    0.00129      0.151    0.00405    0.00135\n",
      "                   D01        121         25   0.000611       0.12   0.000519   9.53e-05\n",
      "                   D10        121          1          0          0          0          0\n",
      "                   D11        121         24    0.00223      0.292    0.00253   0.000579\n",
      "                   D20        121          1          0          0          0          0\n",
      "                   D40        121         37    0.00133      0.189    0.00159   0.000331\n",
      "                   D43        121         74    0.00484      0.459     0.0237    0.00845\n",
      "                   D44        121          3          0          0          0          0\n",
      "Speed: 1.9ms preprocess, 125.1ms inference, 0.0ms loss, 9.5ms postprocess per image\n",
      "Results saved to \u001b[1mRoad Crack Detection\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PREDICTING CRACKS FROM IMAGE\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Charan Chakkara\\Documents\\GitHub\\Road Crack Detection 2\\dataset\\test\\images\\IMG_1864_jpg.rf.89a5204737038a1eea4b7cbac7f43fc1.jpg: 640x640 (no detections), 118.0ms\n",
      "Speed: 0.0ms preprocess, 118.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.yolo.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.yolo.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'D01', 1: 'D10', 2: 'D11', 3: 'D20', 4: 'D40', 5: 'D43', 6: 'D44'}\n",
       " orig_img: array([[[ 98, 109, 113],\n",
       "         [ 98, 109, 113],\n",
       "         [ 99, 110, 114],\n",
       "         ...,\n",
       "         [165, 186, 208],\n",
       "         [188, 206, 229],\n",
       "         [163, 181, 204]],\n",
       " \n",
       "        [[ 98, 109, 113],\n",
       "         [ 99, 110, 114],\n",
       "         [ 99, 110, 114],\n",
       "         ...,\n",
       "         [153, 171, 194],\n",
       "         [167, 185, 208],\n",
       "         [152, 171, 192]],\n",
       " \n",
       "        [[101, 112, 116],\n",
       "         [101, 112, 116],\n",
       "         [102, 113, 117],\n",
       "         ...,\n",
       "         [124, 141, 162],\n",
       "         [148, 165, 186],\n",
       "         [137, 154, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[134, 150, 166],\n",
       "         [127, 143, 159],\n",
       "         [127, 143, 159],\n",
       "         ...,\n",
       "         [ 77,  95, 112],\n",
       "         [ 81,  99, 116],\n",
       "         [ 88, 106, 123]],\n",
       " \n",
       "        [[138, 154, 170],\n",
       "         [141, 157, 173],\n",
       "         [142, 158, 174],\n",
       "         ...,\n",
       "         [ 85, 103, 120],\n",
       "         [ 92, 110, 127],\n",
       "         [ 98, 116, 133]],\n",
       " \n",
       "        [[139, 155, 171],\n",
       "         [154, 170, 186],\n",
       "         [156, 172, 188],\n",
       "         ...,\n",
       "         [111, 129, 146],\n",
       "         [123, 141, 158],\n",
       "         [130, 148, 165]]], dtype=uint8)\n",
       " orig_shape: (640, 640)\n",
       " path: 'C:\\\\Users\\\\Charan Chakkara\\\\Documents\\\\GitHub\\\\Road Crack Detection 2\\\\dataset\\\\test\\\\images\\\\IMG_1864_jpg.rf.89a5204737038a1eea4b7cbac7f43fc1.jpg'\n",
       " probs: None\n",
       " speed: {'preprocess': 0.0, 'inference': 118.02554130554199, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model('./dataset/test/images/IMG_1864_jpg.rf.89a5204737038a1eea4b7cbac7f43fc1.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
